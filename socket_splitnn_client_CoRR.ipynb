{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import PearsonCorrCoef\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "import h5py\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split 3D CNN Client Side\n",
    "This code is the server part of split 3D-CNN model for **multi** client and a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /home/guest2/miniconda3/envs/split_env/lib/python3.9/site-packages (0.56.4)\n",
      "Requirement already satisfied: setuptools in /home/guest2/miniconda3/envs/split_env/lib/python3.9/site-packages (from numba) (66.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /home/guest2/miniconda3/envs/split_env/lib/python3.9/site-packages (from numba) (1.23.5)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/guest2/miniconda3/envs/split_env/lib/python3.9/site-packages (from numba) (0.39.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numba\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET Hyperparameter (**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 3 # number of clients\n",
    "epoch = 50  # default\n",
    "lr = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "torch.manual_seed(777)\n",
    "if device ==\"cuda:1\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_order = int(input(\"client_order(start from 0): \"))\n",
    "client_order = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로\n",
    "            root_dir (string): 모든 이미지가 존재하는 디렉토리 경로\n",
    "            transform (callable, optional): 샘플에 적용될 Optional transform\n",
    "        \"\"\"\n",
    "        self.mri_annotation = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mri_annotation)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        try:        \n",
    "            img_name = os.path.join(self.root_dir,'wm'+ str(self.mri_annotation.iloc[idx, 3]) + '_' + str(self.mri_annotation.iloc[idx, 0]).zfill(7)+ '_ses1' + '_t1w.nii')\n",
    "            mri_image = nib.load(img_name).get_fdata()\n",
    "            mri_age = self.mri_annotation.iloc[idx, 1]\n",
    "            sample = {'image': mri_image, 'mri_age': mri_age}\n",
    "        except:\n",
    "            return None\n",
    "            \n",
    "        return mri_image, mri_age\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "def flatten(lst):\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if type(item) == list :\n",
    "            result += flatten(item)\n",
    "        else:\n",
    "            result += [item]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_train_dataset = MRIDataset(csv_file = './FLdata/2_CoRR/CoRR_Phenotype_train.csv', root_dir = './FLdata/2_CoRR/T1w/wm/')\n",
    "mri_test_dataset = MRIDataset(csv_file = './FLdata/2_CoRR/CoRR_Phenotype_test.csv', root_dir = './FLdata/2_CoRR/T1w/wm/')\n",
    "mri_val_dataset = MRIDataset(csv_file = './FLdata/2_CoRR/CoRR_Phenotype_validation.csv', root_dir = './FLdata/2_CoRR/T1w/wm/')\n",
    "model_PATH = './model/CheckpointCoRR.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(mri_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, drop_last = True)\n",
    "test_loader = DataLoader(mri_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, drop_last = True)\n",
    "val_loader = DataLoader(mri_val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 113, 137, 113])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = next(iter(train_loader))\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other hyperparameters in the model\n",
    "Hyperparameters here should be same with the server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3DModel, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.client_block = nn.Sequential(\n",
    "            # First Block\n",
    "            nn.Conv3d(1, 16, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(16, 16, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            # Second Block\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "    \n",
    "            nn.Conv3d(32, 32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            # Third Block\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool3d(2),\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        self.server_block = nn.Sequential(\n",
    "            \n",
    "            # 4th Block\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(128, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            # 5th Block\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool3d(2),\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(9216, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.client_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN3DModel(\n",
      "  (client_block): Sequential(\n",
      "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (9): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (13): ReLU()\n",
      "    (14): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (15): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "splitnn_client = CNN3DModel().to(device)\n",
    "print(splitnn_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"127.0.0.1\"\n",
    "port = 10080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET TIMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer start!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()    # store start time\n",
    "print(\"timer start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the client socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket()\n",
    "s.connect((host, port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = recv_msg(s)   # get epoch\n",
    "total_batch = len(train_loader)\n",
    "msg = total_batch\n",
    "send_msg(s, msg)   # send total_batch of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss().to(device)\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(splitnn_client.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|███████████████████████████████▊| 192/193 [00:29<00:00,  6.41it/s]\n",
      "Epoch 2:  99%|███████████████████████████████▊| 192/193 [00:29<00:00,  6.59it/s]\n",
      "Epoch 3:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.66it/s]\n",
      "Epoch 4:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.66it/s]\n",
      "Epoch 5:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.65it/s]\n",
      "Epoch 6:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.64it/s]\n",
      "Epoch 7:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.66it/s]\n",
      "Epoch 8:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.65it/s]\n",
      "Epoch 9:  99%|███████████████████████████████▊| 192/193 [00:28<00:00,  6.69it/s]\n",
      "Epoch 10:  99%|██████████████████████████████▊| 192/193 [00:28<00:00,  6.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    client_weights = recv_msg(s)\n",
    "    splitnn_client.load_state_dict(client_weights)\n",
    "    splitnn_client.eval()\n",
    "    i = 1\n",
    "    for images, labels in tqdm(train_loader, desc='Epoch '+str(e+1)):\n",
    "        train = images.view(images.shape[0], 1, images.shape[1], images.shape[2],images.shape[3]).to(device, dtype = torch.float32)\n",
    "        label = labels.to(device)\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagation\n",
    "        outputs = splitnn_client(train)\n",
    "        client_output = outputs.clone().detach().requires_grad_(True)\n",
    "        msg = {\n",
    "            'client_output': client_output,\n",
    "            'label': label\n",
    "        }\n",
    "        send_msg(s, msg)\n",
    "        client_grad = recv_msg(s)\n",
    "        outputs.backward(client_grad)\n",
    "        optimizer.step()\n",
    "        if (i == total_batch):\n",
    "            break;\n",
    "        i = i+1;\n",
    "        del outputs\n",
    "        del client_output\n",
    "    \n",
    "    send_msg(s, splitnn_client.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkingTime of  cuda:1 : 563.3791165351868 sec\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()  #store end time\n",
    "print(\"WorkingTime of \",device ,\": {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
